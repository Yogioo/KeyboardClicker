#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OCRæ–‡å­—è¯†åˆ«ä¸æ ‡ç­¾æ˜¾ç¤ºé›†æˆæ¼”ç¤º
åŸºäºå·²æœ‰æ¨¡å—å®ç°ï¼šæˆªå›¾ => è¯†åˆ«æ–‡å­—ä¸ä½ç½® => åœ¨æ–‡å­—ä½ç½®æ˜¾ç¤ºå”¯ä¸€æ ‡ç­¾
"""

import sys
import os
import signal
import time
import tkinter as tk
from contextlib import contextmanager
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.utils.screenshot import ScreenshotTool
from src.utils.recognition import ScreenRecognizer
from src.utils.screen_labeler import ScreenLabeler

# å…¨å±€ä¸­æ–­æ ‡å¿—
_interrupted = False

@contextmanager
def keyboard_interrupt_handler():
    """é”®ç›˜ä¸­æ–­å¤„ç†ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    global _interrupted
    _interrupted = False
    
    def signal_handler(signum, frame):
        global _interrupted
        _interrupted = True
        print("\n[ä¸­æ–­] æ£€æµ‹åˆ°é”®ç›˜ä¸­æ–­ï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")
        
    old_handler = signal.signal(signal.SIGINT, signal_handler)
    try:
        yield
    finally:
        signal.signal(signal.SIGINT, old_handler)

def countdown_with_interrupt(seconds, message=""):
    """å¯ä¸­æ–­çš„å€’è®¡æ—¶"""
    global _interrupted
    for i in range(seconds, 0, -1):
        if _interrupted:
            print("\næ“ä½œå·²å–æ¶ˆ")
            return False
        print(f"{message}{i}ç§’...", end='\r')
        time.sleep(1)
    if message:
        print(f"{message}å¼€å§‹æ‰§è¡Œï¼")
    return True

class OCRLabelIntegrator:
    """OCRè¯†åˆ«ä¸æ ‡ç­¾æ˜¾ç¤ºé›†æˆå™¨"""
    
    def __init__(self):
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self._screenshot_tool = ScreenshotTool()
        self._recognizer = ScreenRecognizer()
        self._labeler = ScreenLabeler()
        
        # å½“å‰è¯†åˆ«ç»“æœå’Œæ ‡ç­¾æ˜ å°„
        self._current_detections = []
        self._label_mapping = {}
        
        # è¾¹ç•Œæ¡†æ˜¾ç¤º
        self._bbox_windows = []
        self._bbox_root = None
        
        # è®¾ç½®å›è°ƒ
        self._setup_callbacks()
        
        # ä¼˜åŒ–OCRå‚æ•°ä»¥è·å–æ›´å¤šæ–‡å­—
        self._optimize_ocr_settings()
    
    def _setup_callbacks(self):
        """è®¾ç½®ç»„ä»¶å›è°ƒ"""
        self._screenshot_tool.set_screenshot_callback(self._on_screenshot)
        self._screenshot_tool.set_error_callback(self._on_error)
        
        self._recognizer.set_recognition_callback(self._on_recognition)
        self._recognizer.set_error_callback(self._on_error)
        
        self._labeler.SetCallback(self._on_label_success)
        self._labeler.SetErrorCallback(self._on_error)
    
    def _on_screenshot(self, msg):
        print(f"[æˆªå›¾] {msg}")
    
    def _on_recognition(self, msg):
        print(f"[è¯†åˆ«] {msg}")
    
    def _on_label_success(self, msg):
        print(f"[æ ‡ç­¾] {msg}")
    
    def _on_error(self, msg):
        print(f"[é”™è¯¯] {msg}")
    
    def _optimize_ocr_settings(self):
        """ä¼˜åŒ–OCRè®¾ç½®ä»¥è·å–æ›´å¤šæ–‡å­—è¯†åˆ«ç»“æœ"""
        try:
            # è®¾ç½®æ›´å®½æ¾çš„Tesseracté…ç½®
            # --psm 6: å‡è®¾ä¸€ä¸ªç»Ÿä¸€çš„æ–‡æœ¬å—
            # --psm 8: å°†å›¾åƒè§†ä¸ºå•ä¸ªå•è¯
            # --psm 11: ç¨€ç–æ–‡æœ¬ï¼Œå°½å¯èƒ½å¤šåœ°æ‰¾åˆ°æ–‡å­—
            optimized_config = '--oem 3 --psm 11 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å'
            
            self._recognizer.set_tesseract_config(optimized_config)
            print("[ä¼˜åŒ–] å·²è®¾ç½®æ›´å®½æ¾çš„OCRå‚æ•°ä»¥æ£€æµ‹æ›´å¤šæ–‡å­—")
            
        except Exception as e:
            self._on_error(f"OCRå‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")
    
    def SetOCRLowConfidence(self, enable=True):
        """è®¾ç½®æ˜¯å¦å¯ç”¨ä½ç½®ä¿¡åº¦æ–‡å­—æ£€æµ‹"""
        try:
            if enable:
                # é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ä»¥è·å–æ›´å¤šç»“æœ
                print("[è®¾ç½®] å¯ç”¨ä½ç½®ä¿¡åº¦æ–‡å­—æ£€æµ‹æ¨¡å¼")
                self._low_confidence_mode = True
            else:
                print("[è®¾ç½®] ç¦ç”¨ä½ç½®ä¿¡åº¦æ–‡å­—æ£€æµ‹æ¨¡å¼") 
                self._low_confidence_mode = False
                
        except Exception as e:
            self._on_error(f"è®¾ç½®ä½ç½®ä¿¡åº¦æ¨¡å¼å¤±è´¥: {e}")
    
    def RecognizeWithMultipleMethods(self, image_source):
        """ä½¿ç”¨è¶…çº§å¤šç§æ–¹æ³•è¿›è¡Œæ–‡å­—è¯†åˆ«ä»¥è·å–æœ€å¤šç»“æœ"""
        try:
            all_results = []
            
            # æ–¹æ³•1: æ ‡å‡†è¯†åˆ«
            print("[è¯†åˆ«] ä½¿ç”¨æ ‡å‡†å‚æ•°è¯†åˆ«...")
            self._recognizer.set_tesseract_config('--oem 3 --psm 6')
            results1 = self._recognizer.recognize_text(image_source)
            all_results.extend(results1)
            print(f"[è¯†åˆ«] æ ‡å‡†æ–¹æ³•è¯†åˆ«åˆ° {len(results1)} ä¸ªåŒºåŸŸ")
            
            # æ–¹æ³•2: ç¨€ç–æ–‡æœ¬æ¨¡å¼
            print("[è¯†åˆ«] ä½¿ç”¨ç¨€ç–æ–‡æœ¬æ¨¡å¼è¯†åˆ«...")
            self._recognizer.set_tesseract_config('--oem 3 --psm 11')
            results2 = self._recognizer.recognize_text(image_source)
            all_results.extend(results2)
            print(f"[è¯†åˆ«] ç¨€ç–æ–‡æœ¬æ¨¡å¼è¯†åˆ«åˆ° {len(results2)} ä¸ªåŒºåŸŸ")
            
            # æ–¹æ³•3: å•è¯çº§è¯†åˆ«
            print("[è¯†åˆ«] ä½¿ç”¨å•è¯çº§è¯†åˆ«...")
            self._recognizer.set_tesseract_config('--oem 3 --psm 8')
            results3 = self._recognizer.recognize_text(image_source)
            all_results.extend(results3)
            print(f"[è¯†åˆ«] å•è¯çº§è¯†åˆ«åˆ° {len(results3)} ä¸ªåŒºåŸŸ")
            
            # æ–¹æ³•4: å­—ç¬¦çº§è¯†åˆ«
            print("[è¯†åˆ«] ä½¿ç”¨å­—ç¬¦çº§è¯†åˆ«...")
            self._recognizer.set_tesseract_config('--oem 3 --psm 10')
            results4 = self._recognizer.recognize_text(image_source)
            all_results.extend(results4)
            print(f"[è¯†åˆ«] å­—ç¬¦çº§è¯†åˆ«åˆ° {len(results4)} ä¸ªåŒºåŸŸ")
            
            # æ–¹æ³•5: æ— çº¦æŸè¯†åˆ«ï¼ˆæœ€æ¿€è¿›ï¼‰
            print("[è¯†åˆ«] ä½¿ç”¨æ— çº¦æŸæ¨¡å¼è¯†åˆ«...")
            self._recognizer.set_tesseract_config('--oem 3 --psm 13')
            results5 = self._recognizer.recognize_text(image_source)
            all_results.extend(results5)
            print(f"[è¯†åˆ«] æ— çº¦æŸæ¨¡å¼è¯†åˆ«åˆ° {len(results5)} ä¸ªåŒºåŸŸ")
            
            # æ–¹æ³•6: åŸå§‹çº¿æ¡è¯†åˆ«
            print("[è¯†åˆ«] ä½¿ç”¨åŸå§‹çº¿æ¡æ¨¡å¼è¯†åˆ«...")
            self._recognizer.set_tesseract_config('--oem 3 --psm 4')
            results6 = self._recognizer.recognize_text(image_source)
            all_results.extend(results6)
            print(f"[è¯†åˆ«] åŸå§‹çº¿æ¡æ¨¡å¼è¯†åˆ«åˆ° {len(results6)} ä¸ªåŒºåŸŸ")
            
            # æ–¹æ³•7: ä½ç½®ä¿¡åº¦è¯†åˆ«
            print("[è¯†åˆ«] ä½¿ç”¨ä½ç½®ä¿¡åº¦æ¨¡å¼è¯†åˆ«...")
            results7 = self._recognize_with_low_confidence(image_source)
            all_results.extend(results7)
            print(f"[è¯†åˆ«] ä½ç½®ä¿¡åº¦æ¨¡å¼è¯†åˆ«åˆ° {len(results7)} ä¸ªåŒºåŸŸ")
            
            # æ–¹æ³•8: å¤šå°ºåº¦è¯†åˆ«
            print("[è¯†åˆ«] ä½¿ç”¨å¤šå°ºåº¦æ¨¡å¼è¯†åˆ«...")
            results8 = self._recognize_with_multiple_scales(image_source)
            all_results.extend(results8)
            print(f"[è¯†åˆ«] å¤šå°ºåº¦æ¨¡å¼è¯†åˆ«åˆ° {len(results8)} ä¸ªåŒºåŸŸ")
            
            # å»é‡å’Œåˆå¹¶ç»“æœ
            unique_results = self._merge_overlapping_results(all_results)
            print(f"[è¯†åˆ«] åˆå¹¶å»é‡åå…± {len(unique_results)} ä¸ªå”¯ä¸€åŒºåŸŸ")
            
            return unique_results
            
        except Exception as e:
            self._on_error(f"å¤šæ–¹æ³•è¯†åˆ«å¤±è´¥: {e}")
            return []
    
    def _merge_overlapping_results(self, results):
        """åˆå¹¶é‡å çš„è¯†åˆ«ç»“æœ"""
        try:
            if not results:
                return []
            
            # æŒ‰ä½ç½®å»é‡ï¼ˆç›¸è¿‘ä½ç½®çš„ç»“æœåˆå¹¶ï¼‰
            unique_results = []
            merge_threshold = 20  # åƒç´ é˜ˆå€¼
            
            for result in results:
                is_duplicate = False
                
                for existing in unique_results:
                    # è®¡ç®—ä¸­å¿ƒç‚¹è·ç¦»
                    distance = ((result['center_x'] - existing['center_x'])**2 + 
                              (result['center_y'] - existing['center_y'])**2)**0.5
                    
                    if distance < merge_threshold:
                        # å¦‚æœè·ç¦»å¾ˆè¿‘ï¼Œä¿ç•™ç½®ä¿¡åº¦æ›´é«˜çš„
                        if result['confidence'] > existing['confidence']:
                            unique_results.remove(existing)
                            unique_results.append(result)
                        is_duplicate = True
                        break
                
                if not is_duplicate:
                    unique_results.append(result)
            
            # æŒ‰ç½®ä¿¡åº¦æ’åº
            unique_results.sort(key=lambda x: x['confidence'], reverse=True)
            
            return unique_results
            
        except Exception as e:
            self._on_error(f"ç»“æœåˆå¹¶å¤±è´¥: {e}")
            return results
    
    def _recognize_with_low_confidence(self, image_source):
        """ä½¿ç”¨æä½ç½®ä¿¡åº¦é˜ˆå€¼è¿›è¡Œè¯†åˆ«"""
        try:
            # ä¸´æ—¶ä¿®æ”¹è¯†åˆ«å™¨ä»¥æ”¯æŒä½ç½®ä¿¡åº¦
            import pytesseract
            from PIL import Image
            import cv2
            import numpy as np
            
            # è·å–å›¾åƒ
            if isinstance(image_source, str):
                image = cv2.imread(image_source)
            else:
                # å‡è®¾æ˜¯PILå›¾åƒæˆ–numpyæ•°ç»„
                if hasattr(image_source, 'save'):  # PIL Image
                    image = cv2.cvtColor(np.array(image_source), cv2.COLOR_RGB2BGR)
                else:  # numpy array
                    image = image_source
            
            # è½¬æ¢ä¸ºPILæ ¼å¼è¿›è¡ŒOCR
            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            
            # ä½¿ç”¨æä½ç½®ä¿¡åº¦é…ç½®
            config = '--oem 3 --psm 11 -c tessedit_char_confidence=1'
            
            # è·å–è¯¦ç»†OCRæ•°æ®
            data = pytesseract.image_to_data(pil_image, config=config, output_type=pytesseract.Output.DICT)
            
            results = []
            n_boxes = len(data['level'])
            
            for i in range(n_boxes):
                confidence = float(data['conf'][i])
                text = data['text'][i].strip()
                
                # æä½çš„ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆæ¥å—å‡ ä¹æ‰€æœ‰è¯†åˆ«ç»“æœï¼‰
                if confidence > 1 and len(text) > 0:  # åªè¦ç½®ä¿¡åº¦>1%ä¸”æœ‰æ–‡å­—
                    x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]
                    
                    # è¿‡æ»¤è¿‡å°çš„åŒºåŸŸ
                    if w > 3 and h > 3:
                        center_x = x + w // 2
                        center_y = y + h // 2
                        
                        result = {
                            'type': 'text',
                            'text': text,
                            'center_x': center_x,
                            'center_y': center_y,
                            'width': w,
                            'height': h,
                            'confidence': confidence / 100.0,
                            'bbox': (x, y, w, h)
                        }
                        results.append(result)
            
            return results
            
        except Exception as e:
            self._on_error(f"ä½ç½®ä¿¡åº¦è¯†åˆ«å¤±è´¥: {e}")
            return []
    
    def _recognize_with_multiple_scales(self, image_source):
        """ä½¿ç”¨å¤šç§å›¾åƒç¼©æ”¾è¿›è¡Œè¯†åˆ«"""
        try:
            import cv2
            import numpy as np
            from PIL import Image
            
            # è·å–åŸå§‹å›¾åƒ
            if isinstance(image_source, str):
                original_image = cv2.imread(image_source)
            else:
                if hasattr(image_source, 'save'):  # PIL Image
                    original_image = cv2.cvtColor(np.array(image_source), cv2.COLOR_RGB2BGR)
                else:
                    original_image = image_source
            
            all_results = []
            scales = [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]  # ä¸åŒç¼©æ”¾æ¯”ä¾‹
            
            for scale in scales:
                try:
                    # ç¼©æ”¾å›¾åƒ
                    if scale != 1.0:
                        height, width = original_image.shape[:2]
                        new_width = int(width * scale)
                        new_height = int(height * scale)
                        scaled_image = cv2.resize(original_image, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
                    else:
                        scaled_image = original_image.copy()
                    
                    # è½¬æ¢ä¸ºPILæ ¼å¼
                    pil_image = Image.fromarray(cv2.cvtColor(scaled_image, cv2.COLOR_BGR2RGB))
                    
                    # ä½¿ç”¨ç¨€ç–æ–‡æœ¬æ¨¡å¼è¯†åˆ«ç¼©æ”¾åçš„å›¾åƒ
                    self._recognizer.set_tesseract_config('--oem 3 --psm 11')
                    scale_results = self._recognizer.recognize_text(pil_image)
                    
                    # è°ƒæ•´åæ ‡å›åŸå§‹å°ºå¯¸
                    if scale != 1.0:
                        for result in scale_results:
                            result['center_x'] = int(result['center_x'] / scale)
                            result['center_y'] = int(result['center_y'] / scale)
                            result['width'] = int(result['width'] / scale)
                            result['height'] = int(result['height'] / scale)
                            x, y, w, h = result['bbox']
                            result['bbox'] = (int(x / scale), int(y / scale), int(w / scale), int(h / scale))
                    
                    all_results.extend(scale_results)
                    
                except Exception as e:
                    print(f"[è­¦å‘Š] ç¼©æ”¾ {scale} è¯†åˆ«å¤±è´¥: {e}")
                    continue
            
            return all_results
            
        except Exception as e:
            self._on_error(f"å¤šå°ºåº¦è¯†åˆ«å¤±è´¥: {e}")
            return []
    
    def RecognizeWithSuperAggressiveMode(self, image_source):
        """è¶…çº§æ¿€è¿›æ¨¡å¼ï¼šä½¿ç”¨æ‰€æœ‰å¯èƒ½çš„æ–¹æ³•è¯†åˆ«æ–‡å­—"""
        try:
            print("ğŸš€ å¯åŠ¨è¶…çº§æ¿€è¿›è¯†åˆ«æ¨¡å¼...")
            all_results = []
            
            # å…ˆç”¨æ‰€æœ‰æ ‡å‡†æ–¹æ³•
            standard_results = self.RecognizeWithMultipleMethods(image_source)
            all_results.extend(standard_results)
            print(f"[æ¿€è¿›] æ ‡å‡†æ–¹æ³•æ€»è®¡è¯†åˆ«åˆ° {len(standard_results)} ä¸ªåŒºåŸŸ")
            
            # æ·»åŠ å›¾åƒé¢„å¤„ç†å˜ä½“è¯†åˆ«
            preprocessed_results = self._recognize_with_image_variants(image_source)
            all_results.extend(preprocessed_results)
            print(f"[æ¿€è¿›] å›¾åƒå˜ä½“è¯†åˆ«åˆ° {len(preprocessed_results)} ä¸ªåŒºåŸŸ")
            
            # æ·»åŠ æä½é˜ˆå€¼è¯†åˆ«
            extreme_results = self._recognize_with_extreme_settings(image_source)
            all_results.extend(extreme_results)
            print(f"[æ¿€è¿›] æé™è®¾ç½®è¯†åˆ«åˆ° {len(extreme_results)} ä¸ªåŒºåŸŸ")
            
            # æœ€ç»ˆåˆå¹¶å’Œå»é‡
            unique_results = self._merge_overlapping_results(all_results)
            print(f"ğŸ¯ [æ¿€è¿›] è¶…çº§æ¨¡å¼æœ€ç»ˆè¯†åˆ«åˆ° {len(unique_results)} ä¸ªå”¯ä¸€åŒºåŸŸ")
            
            return unique_results
            
        except Exception as e:
            self._on_error(f"è¶…çº§æ¿€è¿›æ¨¡å¼å¤±è´¥: {e}")
            return []
    
    def _recognize_with_image_variants(self, image_source):
        """ä½¿ç”¨å„ç§å›¾åƒé¢„å¤„ç†å˜ä½“è¿›è¡Œè¯†åˆ«"""
        try:
            import cv2
            import numpy as np
            from PIL import Image, ImageEnhance, ImageFilter
            
            # è·å–åŸå§‹å›¾åƒ
            if isinstance(image_source, str):
                original_image = cv2.imread(image_source)
                pil_original = Image.open(image_source)
            else:
                if hasattr(image_source, 'save'):  # PIL Image
                    pil_original = image_source
                    original_image = cv2.cvtColor(np.array(image_source), cv2.COLOR_RGB2BGR)
                else:
                    original_image = image_source
                    pil_original = Image.fromarray(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
            
            all_results = []
            
            # å˜ä½“1: é«˜å¯¹æ¯”åº¦
            print("[å˜ä½“] å¤„ç†é«˜å¯¹æ¯”åº¦å›¾åƒ...")
            try:
                enhancer = ImageEnhance.Contrast(pil_original)
                high_contrast = enhancer.enhance(2.0)
                results1 = self._single_recognize(high_contrast)
                all_results.extend(results1)
                print(f"    é«˜å¯¹æ¯”åº¦è¯†åˆ«åˆ° {len(results1)} ä¸ªåŒºåŸŸ")
            except: pass
            
            # å˜ä½“2: é”åŒ–å›¾åƒ
            print("[å˜ä½“] å¤„ç†é”åŒ–å›¾åƒ...")
            try:
                sharpened = pil_original.filter(ImageFilter.SHARPEN)
                results2 = self._single_recognize(sharpened)
                all_results.extend(results2)
                print(f"    é”åŒ–è¯†åˆ«åˆ° {len(results2)} ä¸ªåŒºåŸŸ")
            except: pass
            
            # å˜ä½“3: äº®åº¦å¢å¼º
            print("[å˜ä½“] å¤„ç†äº®åº¦å¢å¼ºå›¾åƒ...")
            try:
                brightness = ImageEnhance.Brightness(pil_original)
                bright_image = brightness.enhance(1.5)
                results3 = self._single_recognize(bright_image)
                all_results.extend(results3)
                print(f"    äº®åº¦å¢å¼ºè¯†åˆ«åˆ° {len(results3)} ä¸ªåŒºåŸŸ")
            except: pass
            
            # å˜ä½“4: äºŒå€¼åŒ–å¤„ç†
            print("[å˜ä½“] å¤„ç†äºŒå€¼åŒ–å›¾åƒ...")
            try:
                gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)
                _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
                binary_pil = Image.fromarray(binary)
                results4 = self._single_recognize(binary_pil)
                all_results.extend(results4)
                print(f"    äºŒå€¼åŒ–è¯†åˆ«åˆ° {len(results4)} ä¸ªåŒºåŸŸ")
            except: pass
            
            # å˜ä½“5: è‡ªé€‚åº”é˜ˆå€¼
            print("[å˜ä½“] å¤„ç†è‡ªé€‚åº”é˜ˆå€¼å›¾åƒ...")
            try:
                gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)
                adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
                adaptive_pil = Image.fromarray(adaptive)
                results5 = self._single_recognize(adaptive_pil)
                all_results.extend(results5)
                print(f"    è‡ªé€‚åº”é˜ˆå€¼è¯†åˆ«åˆ° {len(results5)} ä¸ªåŒºåŸŸ")
            except: pass
            
            # å˜ä½“6: å½¢æ€å­¦æ“ä½œ
            print("[å˜ä½“] å¤„ç†å½¢æ€å­¦æ“ä½œå›¾åƒ...")
            try:
                gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)
                kernel = np.ones((2,2), np.uint8)
                morph = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)
                morph_pil = Image.fromarray(morph)
                results6 = self._single_recognize(morph_pil)
                all_results.extend(results6)
                print(f"    å½¢æ€å­¦æ“ä½œè¯†åˆ«åˆ° {len(results6)} ä¸ªåŒºåŸŸ")
            except: pass
            
            return all_results
            
        except Exception as e:
            self._on_error(f"å›¾åƒå˜ä½“è¯†åˆ«å¤±è´¥: {e}")
            return []
    
    def _single_recognize(self, pil_image):
        """å¯¹å•ä¸ªå›¾åƒè¿›è¡Œå¿«é€Ÿè¯†åˆ«"""
        try:
            self._recognizer.set_tesseract_config('--oem 3 --psm 11')
            return self._recognizer.recognize_text(pil_image)
        except:
            return []
    
    def _recognize_with_extreme_settings(self, image_source):
        """ä½¿ç”¨æé™è®¾ç½®è¿›è¡Œè¯†åˆ«"""
        try:
            import pytesseract
            from PIL import Image
            import cv2
            import numpy as np
            
            # è·å–å›¾åƒ
            if isinstance(image_source, str):
                image = cv2.imread(image_source)
            else:
                if hasattr(image_source, 'save'):  # PIL Image
                    image = cv2.cvtColor(np.array(image_source), cv2.COLOR_RGB2BGR)
                else:
                    image = image_source
            
            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            
            # æé™é…ç½®ï¼šå…è®¸æ‰€æœ‰å­—ç¬¦ï¼Œæœ€ä½ç½®ä¿¡åº¦
            extreme_configs = [
                '--oem 3 --psm 13 -c tessedit_char_confidence=0',
                '--oem 1 --psm 11 -c tessedit_char_confidence=0',
                '--oem 2 --psm 13 -c tessedit_char_confidence=0',
                '--oem 3 --psm 12 -c tessedit_char_confidence=0'
            ]
            
            all_results = []
            
            for config in extreme_configs:
                try:
                    data = pytesseract.image_to_data(pil_image, config=config, output_type=pytesseract.Output.DICT)
                    
                    for i in range(len(data['level'])):
                        confidence = float(data['conf'][i])
                        text = data['text'][i].strip()
                        
                        # å‡ ä¹æ¥å—æ‰€æœ‰ç»“æœ
                        if confidence >= 0 and len(text) > 0:
                            x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]
                            
                            if w > 1 and h > 1:  # æœ€å°å°ºå¯¸æ£€æŸ¥
                                result = {
                                    'type': 'text',
                                    'text': text,
                                    'center_x': x + w // 2,
                                    'center_y': y + h // 2,
                                    'width': w,
                                    'height': h,
                                    'confidence': max(0.01, confidence / 100.0),  # ç¡®ä¿æœ€å°ç½®ä¿¡åº¦
                                    'bbox': (x, y, w, h)
                                }
                                all_results.append(result)
                except:
                    continue
            
            return all_results
            
        except Exception as e:
            self._on_error(f"æé™è®¾ç½®è¯†åˆ«å¤±è´¥: {e}")
            return []
    
    def ShowTextBoundingBoxes(self, duration=2.0):
        """æ˜¾ç¤ºæ–‡å­—è¯†åˆ«çš„è¾¹ç•Œæ¡†"""
        try:
            if not self._current_detections:
                self._on_error("æ²¡æœ‰è¯†åˆ«ç»“æœï¼Œè¯·å…ˆæ‰§è¡Œæˆªå›¾è¯†åˆ«")
                return False
            
            # æ¸…ç†ä¹‹å‰çš„è¾¹ç•Œæ¡†
            self.HideBoundingBoxes()
            
            # åˆ›å»ºæ ¹çª—å£ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            if self._bbox_root is None:
                self._bbox_root = tk.Tk()
                self._bbox_root.withdraw()  # éšè—ä¸»çª—å£
            
            print(f"[è¾¹ç•Œæ¡†] æ˜¾ç¤º {len(self._current_detections)} ä¸ªæ–‡å­—åŒºåŸŸçš„è¾¹ç•Œæ¡†")
            
            # ä¸ºæ¯ä¸ªæ£€æµ‹ç»“æœåˆ›å»ºè¾¹ç•Œæ¡†çª—å£
            for detection in self._current_detections:
                bbox_window = self._create_bbox_window(detection)
                if bbox_window:
                    self._bbox_windows.append(bbox_window)
            
            # å¦‚æœæŒ‡å®šäº†æŒç»­æ—¶é—´ï¼Œåˆ™è‡ªåŠ¨éšè—
            if duration and duration > 0:
                self._bbox_root.after(int(duration * 1000), self.HideBoundingBoxes)
            
            return True
            
        except Exception as e:
            self._on_error(f"æ˜¾ç¤ºè¾¹ç•Œæ¡†å¤±è´¥: {e}")
            return False
    
    def _create_bbox_window(self, detection):
        """åˆ›å»ºå•ä¸ªè¾¹ç•Œæ¡†çª—å£"""
        try:
            x, y, w, h = detection['bbox']
            
            # åˆ›å»ºé€æ˜çª—å£
            bbox_window = tk.Toplevel(self._bbox_root)
            bbox_window.overrideredirect(True)  # æ— è¾¹æ¡†
            bbox_window.attributes('-topmost', True)  # ç½®é¡¶
            bbox_window.attributes('-alpha', 0.8)  # é€æ˜åº¦
            
            # è®¾ç½®çª—å£ä½ç½®å’Œå¤§å°
            bbox_window.geometry(f"{w}x{h}+{x}+{y}")
            
            # åˆ›å»ºç”»å¸ƒç»˜åˆ¶ç©ºå¿ƒçŸ©å½¢
            canvas = tk.Canvas(
                bbox_window, 
                width=w, 
                height=h,
                highlightthickness=0,
                bg='black'
            )
            canvas.pack()
            
            # ç»˜åˆ¶ç©ºå¿ƒçŸ©å½¢ï¼ˆçº¢è‰²è¾¹æ¡†ï¼Œé€æ˜å†…éƒ¨ï¼‰
            canvas.create_rectangle(
                2, 2, w-2, h-2,
                outline='red',
                fill='',
                width=2
            )
            
            # è®¾ç½®é€æ˜èƒŒæ™¯
            bbox_window.wm_attributes('-transparentcolor', 'black')
            
            return bbox_window
            
        except Exception as e:
            self._on_error(f"åˆ›å»ºè¾¹ç•Œæ¡†çª—å£å¤±è´¥: {e}")
            return None
    
    def HideBoundingBoxes(self):
        """éšè—æ‰€æœ‰è¾¹ç•Œæ¡†"""
        try:
            for window in self._bbox_windows:
                try:
                    window.destroy()
                except:
                    pass
            self._bbox_windows.clear()
            
            if self._bbox_root:
                try:
                    self._bbox_root.quit()
                    self._bbox_root.destroy()
                    self._bbox_root = None
                except:
                    pass
            
            print("[è¾¹ç•Œæ¡†] æ‰€æœ‰è¾¹ç•Œæ¡†å·²éšè—")
            
        except Exception as e:
            self._on_error(f"éšè—è¾¹ç•Œæ¡†å¤±è´¥: {e}")
    
    def CaptureAndRecognize(self, save_screenshot=True, region=None, use_multiple_methods=False, use_super_aggressive=False):
        """æˆªå›¾å¹¶è¯†åˆ«æ–‡å­—"""
        try:
            # 1. æˆªå›¾
            if region is None:
                # å…¨å±æˆªå›¾
                if save_screenshot:
                    screenshot_path = self._screenshot_tool.capture_and_save_full_screen("ocr_capture.png")
                    print(f"[æˆªå›¾] å…¨å±æˆªå›¾å·²ä¿å­˜: {screenshot_path}")
                else:
                    screenshot = self._screenshot_tool.capture_full_screen()
                    screenshot_path = None
            else:
                # åŒºåŸŸæˆªå›¾
                x, y, width, height = region
                if save_screenshot:
                    screenshot_path = self._screenshot_tool.capture_and_save_region(
                        x, y, width, height, "ocr_region.png"
                    )
                    print(f"[æˆªå›¾] åŒºåŸŸæˆªå›¾å·²ä¿å­˜: {screenshot_path}")
                else:
                    screenshot = self._screenshot_tool.capture_region(x, y, width, height)
                    screenshot_path = None
            
            # 2. æ–‡å­—è¯†åˆ«
            if use_super_aggressive:
                # ä½¿ç”¨è¶…çº§æ¿€è¿›æ¨¡å¼
                if save_screenshot and screenshot_path:
                    text_results = self.RecognizeWithSuperAggressiveMode(screenshot_path)
                else:
                    text_results = self.RecognizeWithSuperAggressiveMode(screenshot)
            elif use_multiple_methods:
                # ä½¿ç”¨å¤šç§æ–¹æ³•è¿›è¡Œè¯†åˆ«ä»¥è·å–æ›´å¤šç»“æœ
                if save_screenshot and screenshot_path:
                    text_results = self.RecognizeWithMultipleMethods(screenshot_path)
                else:
                    text_results = self.RecognizeWithMultipleMethods(screenshot)
            else:
                # ä½¿ç”¨æ ‡å‡†æ–¹æ³•è¯†åˆ«
                if save_screenshot and screenshot_path:
                    text_results = self._recognizer.recognize_text(screenshot_path)
                else:
                    text_results = self._recognizer.recognize_text(screenshot)
            
            # 3. è°ƒæ•´åæ ‡ï¼ˆå¦‚æœæ˜¯åŒºåŸŸæˆªå›¾ï¼‰
            if region is not None:
                offset_x, offset_y = region[0], region[1]
                for result in text_results:
                    result['center_x'] += offset_x
                    result['center_y'] += offset_y
                    # æ›´æ–°bbox
                    x, y, w, h = result['bbox']
                    result['bbox'] = (x + offset_x, y + offset_y, w, h)
            
            self._current_detections = text_results
            print(f"[è¯†åˆ«] å…±è¯†åˆ«åˆ° {len(text_results)} ä¸ªæ–‡å­—åŒºåŸŸ")
            
            return len(text_results) > 0
            
        except Exception as e:
            self._on_error(f"æˆªå›¾è¯†åˆ«å¤±è´¥: {e}")
            return False
    
    def ShowTextLabels(self, max_labels=None, duration=None):
        """ä¸ºè¯†åˆ«åˆ°çš„æ–‡å­—æ˜¾ç¤ºæ ‡ç­¾"""
        try:
            if not self._current_detections:
                self._on_error("æ²¡æœ‰è¯†åˆ«ç»“æœï¼Œè¯·å…ˆæ‰§è¡Œæˆªå›¾è¯†åˆ«")
                return False
            
            # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œå¦‚æœæœ‰max_labelsé™åˆ¶åˆ™åº”ç”¨
            detections_sorted = sorted(
                self._current_detections, 
                key=lambda x: x['confidence'], 
                reverse=True
            )
            
            if max_labels is not None:
                detections_to_label = detections_sorted[:max_labels]
            else:
                detections_to_label = detections_sorted
            
            # ä½¿ç”¨ScreenLabelerçš„æ ‡ç­¾ç”Ÿæˆç®—æ³•
            labels = self._labeler._GenerateLabelList(len(detections_to_label))
            
            # ä¸ºæ¯ä¸ªæ–‡å­—åŒºåŸŸåˆ›å»ºæ ‡ç­¾å…ƒç´ 
            label_elements = []
            self._label_mapping.clear()
            
            for i, (detection, label) in enumerate(zip(detections_to_label, labels)):
                element = {
                    'center_x': detection['center_x'],
                    'center_y': detection['center_y'],
                    'text': label,  # ä½¿ç”¨ç”Ÿæˆçš„æ ‡ç­¾è€Œä¸æ˜¯åŸæ–‡å­—
                    'type': 'text'
                }
                label_elements.append(element)
                
                # ä¿å­˜æ ‡ç­¾æ˜ å°„
                self._label_mapping[label] = {
                    'detection': detection,
                    'element': element
                }
            
            # æ˜¾ç¤ºæ ‡ç­¾
            success = self._labeler.ShowLabels(label_elements, duration)
            
            if success:
                print(f"[æ ‡ç­¾] ä¸º {len(label_elements)} ä¸ªæ–‡å­—åŒºåŸŸæ˜¾ç¤ºäº†æ ‡ç­¾")
                return True
            else:
                self._on_error("æ ‡ç­¾æ˜¾ç¤ºå¤±è´¥")
                return False
                
        except Exception as e:
            self._on_error(f"æ ‡ç­¾æ˜¾ç¤ºå¤±è´¥: {e}")
            return False
    
    def AnalyzeAndLabel(self, region=None, duration=None, max_labels=None, show_boxes=True, use_multiple_methods=False, use_super_aggressive=False):
        """ä¸€é”®åˆ†æï¼šæˆªå›¾ => è¯†åˆ« => æ˜¾ç¤ºæ ‡ç­¾"""
        try:
            if use_super_aggressive:
                print("\nğŸš€ === å¼€å§‹è¶…çº§æ¿€è¿›OCRåˆ†ææµç¨‹ ===")
                print("âš ï¸  è­¦å‘Šï¼šè¿™å°†ä½¿ç”¨æ‰€æœ‰å¯èƒ½çš„è¯†åˆ«æ–¹æ³•ï¼Œè€—æ—¶è¾ƒé•¿ä½†è¯†åˆ«æœ€å…¨é¢")
            elif use_multiple_methods:
                print("\n=== å¼€å§‹æ·±åº¦OCRåˆ†ææµç¨‹ï¼ˆå¤šæ–¹æ³•è¯†åˆ«ï¼‰===")
            else:
                print("\n=== å¼€å§‹OCRåˆ†ææµç¨‹ ===")
            
            # 1. æˆªå›¾å¹¶è¯†åˆ«
            if not self.CaptureAndRecognize(region=region, use_multiple_methods=use_multiple_methods, use_super_aggressive=use_super_aggressive):
                return False
            
            # 2. æ˜¾ç¤ºè¾¹ç•Œæ¡†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if show_boxes:
                print("[æµç¨‹] é¦–å…ˆæ˜¾ç¤ºæ–‡å­—è¾¹ç•Œæ¡†...")
                if self.ShowTextBoundingBoxes(duration=3.0):
                    print("[æµç¨‹] è¾¹ç•Œæ¡†æ˜¾ç¤º3ç§’ï¼Œç„¶åæ˜¾ç¤ºæ ‡ç­¾...")
                    time.sleep(3)
                    self.HideBoundingBoxes()
            
            # 3. æ˜¾ç¤ºæ ‡ç­¾
            if not self.ShowTextLabels(max_labels=max_labels, duration=duration):
                return False
            
            # 4. è¾“å‡ºç»“æœæ‘˜è¦
            print(f"\n=== åˆ†æå®Œæˆ ===")
            print(f"è¯†åˆ«ç»“æœ: {len(self._current_detections)} ä¸ªæ–‡å­—åŒºåŸŸ")
            if max_labels is not None:
                displayed_count = min(len(self._current_detections), max_labels)
                print(f"æ˜¾ç¤ºæ ‡ç­¾: {displayed_count} ä¸ªï¼ˆé™åˆ¶: {max_labels}ï¼‰")
            else:
                print(f"æ˜¾ç¤ºæ ‡ç­¾: {len(self._label_mapping)} ä¸ªï¼ˆæ— é™åˆ¶ï¼‰")
            
            # æ˜¾ç¤ºæ ‡ç­¾æ˜ å°„
            if self._label_mapping:
                print("\næ ‡ç­¾æ˜ å°„:")
                for label, info in list(self._label_mapping.items())[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    detection = info['detection']
                    print(f"  {label}: '{detection['text']}' ç½®ä¿¡åº¦:{detection['confidence']:.2f} ä½ç½®:({detection['center_x']}, {detection['center_y']})")
            
            return True
            
        except Exception as e:
            self._on_error(f"åˆ†ææµç¨‹å¤±è´¥: {e}")
            return False
    
    def HideLabels(self):
        """éšè—æ‰€æœ‰æ ‡ç­¾å’Œè¾¹ç•Œæ¡†"""
        try:
            # éšè—æ ‡ç­¾
            self._labeler.HideLabels()
            self._label_mapping.clear()
            
            # éšè—è¾¹ç•Œæ¡†
            self.HideBoundingBoxes()
            
            print("[æ¸…ç†] æ‰€æœ‰æ ‡ç­¾å’Œè¾¹ç•Œæ¡†å·²éšè—")
        except Exception as e:
            self._on_error(f"éšè—æ ‡ç­¾å¤±è´¥: {e}")
    
    def GetDetectionByLabel(self, label):
        """æ ¹æ®æ ‡ç­¾è·å–å¯¹åº”çš„è¯†åˆ«ç»“æœ"""
        return self._label_mapping.get(label, {}).get('detection')
    
    def GetCurrentDetections(self):
        """è·å–å½“å‰è¯†åˆ«ç»“æœ"""
        return self._current_detections.copy()
    
    def GetLabelMappings(self):
        """è·å–æ ‡ç­¾æ˜ å°„"""
        return self._label_mapping.copy()

def demo_ocr_label_integration():
    """æ¼”ç¤ºOCRè¯†åˆ«ä¸æ ‡ç­¾æ˜¾ç¤ºé›†æˆåŠŸèƒ½"""
    print("=== OCRæ–‡å­—è¯†åˆ«ä¸æ ‡ç­¾æ˜¾ç¤ºé›†æˆæ¼”ç¤º ===")
    print("åŠŸèƒ½: æˆªå›¾ => è¯†åˆ«æ–‡å­—ä¸ä½ç½® => åœ¨æ–‡å­—ä½ç½®æ˜¾ç¤ºå”¯ä¸€æ ‡ç­¾")
    print("æç¤º: æŒ‰ Ctrl+C å¯ä»¥éšæ—¶å®‰å…¨é€€å‡º")
    
    integrator = OCRLabelIntegrator()
    
    with keyboard_interrupt_handler():
        try:
            print("\n=== æ¼”ç¤º1: å…¨å±æ–‡å­—è¯†åˆ«ä¸æ ‡ç­¾ ===")
            if countdown_with_interrupt(3, "å…¨å±åˆ†æå€’è®¡æ—¶: "):
                if not _interrupted:
                    success = integrator.AnalyzeAndLabel(duration=5.0)
                    if success:
                        print("\næ ‡ç­¾å°†æ˜¾ç¤º5ç§’...")
                        time.sleep(5)
            
            if _interrupted:
                return
                
            print("\n=== æ¼”ç¤º2: å±å¹•ä¸­å¿ƒåŒºåŸŸåˆ†æ ===")
            if countdown_with_interrupt(2, "åŒºåŸŸåˆ†æå€’è®¡æ—¶: "):
                if not _interrupted:
                    # åˆ†æå±å¹•ä¸­å¿ƒ800x600åŒºåŸŸ
                    screen_width, screen_height = integrator._screenshot_tool.get_screen_size()
                    x = (screen_width - 800) // 2
                    y = (screen_height - 600) // 2
                    region = (x, y, 800, 600)
                    
                    success = integrator.AnalyzeAndLabel(region=region, duration=0)
                    if success:
                        print("\næ ‡ç­¾æ°¸ä¹…æ˜¾ç¤ºï¼ŒæŒ‰Enterç»§ç»­...")
                        input()
            
            if _interrupted:
                return
                
            print("\n=== æ¼”ç¤º3: æ·±åº¦è¯†åˆ«æ¨¡å¼ ===")
            print("ä½¿ç”¨å¤šç§OCRæ–¹æ³•è¯†åˆ«æ›´å¤šæ–‡å­—...")
            # å·¦ä¸Šè§’åŒºåŸŸ
            region = (50, 50, 600, 400)
            success = integrator.AnalyzeAndLabel(
                region=region, 
                duration=3.0, 
                use_multiple_methods=True
            )
            if success:
                print(f"\næ·±åº¦è¯†åˆ« {region} å®Œæˆï¼Œåº”è¯¥è¯†åˆ«åˆ°æ›´å¤šæ–‡å­—ï¼æ ‡ç­¾æ˜¾ç¤º3ç§’...")
                time.sleep(3)
            
            # æ¸…ç†æ ‡ç­¾
            integrator.HideLabels()
            
            print("\n=== æ¼”ç¤ºå®Œæˆ ===")
            
        except KeyboardInterrupt:
            print("\n[ä¸­æ–­] æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            # ç¡®ä¿æ¸…ç†
            try:
                integrator.HideLabels()
            except:
                pass

def interactive_demo():
    """äº¤äº’å¼æ¼”ç¤º"""
    print("\n=== äº¤äº’å¼OCRæ ‡ç­¾æ¼”ç¤º ===")
    print("æç¤º: åœ¨ä»»ä½•è¾“å…¥æç¤ºå¤„ï¼ŒæŒ‰ Ctrl+C å¯ä»¥å®‰å…¨é€€å‡º")
    
    integrator = OCRLabelIntegrator()
    
    with keyboard_interrupt_handler():
        while not _interrupted:
            try:
                print("\nè¯·é€‰æ‹©æ“ä½œ:")
                print("1. å…¨å±æ–‡å­—è¯†åˆ«ä¸æ ‡ç­¾")
                print("2. å±å¹•ä¸­å¿ƒåŒºåŸŸåˆ†æ")
                print("3. è‡ªå®šä¹‰åŒºåŸŸåˆ†æ")
                print("4. æ·±åº¦è¯†åˆ«æ¨¡å¼ï¼ˆå¤šæ–¹æ³•è¯†åˆ«æ›´å¤šæ–‡å­—ï¼‰")
                print("5. ğŸš€ è¶…çº§æ¿€è¿›æ¨¡å¼ï¼ˆæœ€å…¨é¢è¯†åˆ«ï¼Œè€—æ—¶é•¿ï¼‰")
                print("6. ä»…æˆªå›¾è¯†åˆ«ï¼ˆä¸æ˜¾ç¤ºæ ‡ç­¾ï¼‰")
                print("7. ä¸ºå½“å‰è¯†åˆ«ç»“æœæ˜¾ç¤ºæ ‡ç­¾")
                print("8. æ˜¾ç¤ºå½“å‰è¯†åˆ«ç»“æœçš„è¾¹ç•Œæ¡†")
                print("9. æŸ¥çœ‹å½“å‰è¯†åˆ«ç»“æœ")
                print("10. éšè—æ‰€æœ‰æ ‡ç­¾å’Œè¾¹ç•Œæ¡†")
                print("0. é€€å‡º")
                
                choice = input("è¯·è¾“å…¥é€‰æ‹© (0-10): ").strip()
                
                if _interrupted:
                    break
                    
                if choice == '1':
                    duration = input("æ ‡ç­¾æ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼Œç©º=æ°¸ä¹…ï¼‰: ").strip()
                    duration = float(duration) if duration else None
                    print("è¿›è¡Œå…¨å±åˆ†æ...")
                    integrator.AnalyzeAndLabel(duration=duration)
                    
                elif choice == '2':
                    width = int(input("åŒºåŸŸå®½åº¦ï¼ˆé»˜è®¤800ï¼‰: ") or "800")
                    height = int(input("åŒºåŸŸé«˜åº¦ï¼ˆé»˜è®¤600ï¼‰: ") or "600")
                    
                    screen_width, screen_height = integrator._screenshot_tool.get_screen_size()
                    x = (screen_width - width) // 2
                    y = (screen_height - height) // 2
                    region = (x, y, width, height)
                    
                    print(f"åˆ†æå±å¹•ä¸­å¿ƒåŒºåŸŸ {region}...")
                    integrator.AnalyzeAndLabel(region=region)
                    
                elif choice == '3':
                    x = int(input("åŒºåŸŸXåæ ‡: ") or "100")
                    y = int(input("åŒºåŸŸYåæ ‡: ") or "100")
                    width = int(input("åŒºåŸŸå®½åº¦: ") or "400")
                    height = int(input("åŒºåŸŸé«˜åº¦: ") or "300")
                    max_labels = int(input("æœ€å¤§æ ‡ç­¾æ•°ï¼ˆé»˜è®¤100ï¼‰: ") or "100")
                    
                    region = (x, y, width, height)
                    print(f"åˆ†æè‡ªå®šä¹‰åŒºåŸŸ {region}...")
                    integrator.AnalyzeAndLabel(region=region, max_labels=max_labels)
                    
                elif choice == '4':
                    print("æ·±åº¦è¯†åˆ«æ¨¡å¼ï¼šä½¿ç”¨å¤šç§OCRæ–¹æ³•è¯†åˆ«æ›´å¤šæ–‡å­—...")
                    region_choice = input("åŒºåŸŸç±»å‹ï¼ˆ1=å…¨å±ï¼Œ2=è‡ªå®šä¹‰ï¼‰: ").strip()
                    if region_choice == '2':
                        x = int(input("Xåæ ‡: ") or "0")
                        y = int(input("Yåæ ‡: ") or "0")
                        width = int(input("å®½åº¦: ") or "800")
                        height = int(input("é«˜åº¦: ") or "600")
                        region = (x, y, width, height)
                    else:
                        region = None
                    
                    duration = input("æ ‡ç­¾æ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼Œç©º=æ°¸ä¹…ï¼‰: ").strip()
                    duration = float(duration) if duration else None
                    
                    print("âš ï¸  æ·±åº¦è¯†åˆ«éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
                    success = integrator.AnalyzeAndLabel(
                        region=region, 
                        duration=duration, 
                        use_multiple_methods=True
                    )
                    if success:
                        print("âœ“ æ·±åº¦è¯†åˆ«å®Œæˆï¼åº”è¯¥èƒ½æ£€æµ‹åˆ°æ›´å¤šæ–‡å­—åŒºåŸŸ")
                    
                elif choice == '5':
                    print("ğŸš€ è¶…çº§æ¿€è¿›æ¨¡å¼ï¼šä½¿ç”¨æ‰€æœ‰å¯èƒ½çš„è¯†åˆ«æ–¹æ³•...")
                    print("âš ï¸  æ³¨æ„ï¼šè¿™ä¸ªæ¨¡å¼ä¼šä½¿ç”¨å¤šç§å›¾åƒé¢„å¤„ç†å’Œæä½ç½®ä¿¡åº¦é˜ˆå€¼")
                    print("âš ï¸  é¢„è®¡è€—æ—¶ï¼š1-3åˆ†é’Ÿï¼Œä½†èƒ½è¯†åˆ«åˆ°æœ€å¤šçš„æ–‡å­—")
                    
                    confirm = input("ç¡®è®¤å¯åŠ¨è¶…çº§æ¿€è¿›æ¨¡å¼ï¼Ÿ(y/N): ").strip().lower()
                    if confirm != 'y':
                        print("å·²å–æ¶ˆ")
                        continue
                    
                    region_choice = input("åŒºåŸŸç±»å‹ï¼ˆ1=å…¨å±ï¼Œ2=è‡ªå®šä¹‰ï¼‰: ").strip()
                    if region_choice == '2':
                        x = int(input("Xåæ ‡: ") or "0")
                        y = int(input("Yåæ ‡: ") or "0")
                        width = int(input("å®½åº¦: ") or "800")
                        height = int(input("é«˜åº¦: ") or "600")
                        region = (x, y, width, height)
                    else:
                        region = None
                    
                    duration = input("æ ‡ç­¾æ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼Œç©º=æ°¸ä¹…ï¼‰: ").strip()
                    duration = float(duration) if duration else None
                    
                    print("\nğŸš€ å¯åŠ¨è¶…çº§æ¿€è¿›è¯†åˆ«ï¼Œè¯·è€å¿ƒç­‰å¾…...")
                    success = integrator.AnalyzeAndLabel(
                        region=region, 
                        duration=duration, 
                        use_super_aggressive=True
                    )
                    if success:
                        print("ğŸ¯ è¶…çº§æ¿€è¿›è¯†åˆ«å®Œæˆï¼è¿™æ˜¯èƒ½è¯†åˆ«åˆ°çš„æœ€å¤šæ–‡å­—äº†ï¼")
                    
                elif choice == '6':
                    region_choice = input("åŒºåŸŸç±»å‹ï¼ˆ1=å…¨å±ï¼Œ2=è‡ªå®šä¹‰ï¼‰: ").strip()
                    if region_choice == '2':
                        x = int(input("Xåæ ‡: ") or "0")
                        y = int(input("Yåæ ‡: ") or "0")
                        width = int(input("å®½åº¦: ") or "800")
                        height = int(input("é«˜åº¦: ") or "600")
                        region = (x, y, width, height)
                    else:
                        region = None
                    
                    success = integrator.CaptureAndRecognize(region=region)
                    if success:
                        print("âœ“ æˆªå›¾è¯†åˆ«å®Œæˆï¼Œä½¿ç”¨é€‰é¡¹7æ˜¾ç¤ºæ ‡ç­¾")
                    
                elif choice == '7':
                    max_labels = int(input("æœ€å¤§æ ‡ç­¾æ•°ï¼ˆé»˜è®¤100ï¼‰: ") or "100")
                    duration = input("æ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼Œç©º=æ°¸ä¹…ï¼‰: ").strip()
                    duration = float(duration) if duration else None
                    
                    integrator.ShowTextLabels(max_labels=max_labels, duration=duration)
                    
                elif choice == '8':
                    duration = input("è¾¹ç•Œæ¡†æ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼Œç©º=æ°¸ä¹…ï¼‰: ").strip()
                    duration = float(duration) if duration else None
                    integrator.ShowTextBoundingBoxes(duration=duration)
                    
                elif choice == '9':
                    detections = integrator.GetCurrentDetections()
                    mappings = integrator.GetLabelMappings()
                    
                    if detections:
                        print(f"\nå½“å‰è¯†åˆ«ç»“æœ ({len(detections)} ä¸ª):")
                        for i, detection in enumerate(detections[:10]):
                            print(f"  {i+1}. '{detection['text']}' - ç½®ä¿¡åº¦:{detection['confidence']:.2f} ä½ç½®:({detection['center_x']}, {detection['center_y']})")
                    else:
                        print("å½“å‰æ²¡æœ‰è¯†åˆ«ç»“æœ")
                        
                    if mappings:
                        print(f"\nå½“å‰æ ‡ç­¾æ˜ å°„ ({len(mappings)} ä¸ª):")
                        for label, info in list(mappings.items())[:10]:
                            detection = info['detection']
                            print(f"  {label}: '{detection['text']}'")
                    
                elif choice == '10':
                    integrator.HideLabels()
                    
                elif choice == '0':
                    print("é€€å‡ºæ¼”ç¤º")
                    break
                    
                else:
                    print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                    
            except KeyboardInterrupt:
                print("\n[ä¸­æ–­] æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
                break
            except ValueError:
                print("è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥")
            except Exception as e:
                print(f"æ“ä½œå¤±è´¥: {e}")
                
        if _interrupted:
            print("\n[ä¸­æ–­] äº¤äº’å¼æ¼”ç¤ºå·²å®‰å…¨é€€å‡º")
        
        # æ¸…ç†
        try:
            integrator.HideLabels()
        except:
            pass

if __name__ == "__main__":
    print("ğŸš€ OCRæ–‡å­—è¯†åˆ«ä¸æ ‡ç­¾æ˜¾ç¤ºé›†æˆæ¼”ç¤ºç¨‹åºï¼ˆè¶…å¼ºç‰ˆï¼‰")
    print("åŠŸèƒ½æµç¨‹: æˆªå›¾ => è¯†åˆ«æ–‡å­— => æ˜¾ç¤ºè¾¹ç•Œæ¡† => æ˜¾ç¤ºå”¯ä¸€æ ‡ç­¾")
    print("è¯†åˆ«æ¨¡å¼:")
    print("  ğŸ“Š æ ‡å‡†æ¨¡å¼ï¼šå¿«é€Ÿè¯†åˆ«å¸¸è§æ–‡å­—")
    print("  ğŸ” æ·±åº¦æ¨¡å¼ï¼šä½¿ç”¨8ç§æ–¹æ³•è¯†åˆ«æ›´å¤šæ–‡å­—")
    print("  ğŸš€ è¶…çº§æ¿€è¿›æ¨¡å¼ï¼šä½¿ç”¨æ‰€æœ‰å¯èƒ½æ–¹æ³•ï¼Œè¯†åˆ«æœ€å…¨é¢ï¼ˆè€—æ—¶é•¿ï¼‰")
    print("æ–°ç‰¹æ€§: âœ“ æ— æ ‡ç­¾æ•°é‡ä¸Šé™ âœ“ è¾¹ç•Œæ¡†é¢„è§ˆ âœ“ å¤šå°ºåº¦è¯†åˆ« âœ“ æä½ç½®ä¿¡åº¦é˜ˆå€¼")
    print("ä¾èµ–: ScreenshotTool + ScreenRecognizer + ScreenLabeler")
    print("æç¤º: æŒ‰ Ctrl+C å¯ä»¥éšæ—¶å®‰å…¨é€€å‡º")
    
    try:
        demo_type = input("\né€‰æ‹©æ¼”ç¤ºç±»å‹ (1=è‡ªåŠ¨æ¼”ç¤º, 2=äº¤äº’å¼æ¼”ç¤º): ").strip()
        
        if demo_type == '1':
            demo_ocr_label_integration()
        elif demo_type == '2':
            interactive_demo()
        else:
            print("é»˜è®¤è¿è¡Œè‡ªåŠ¨æ¼”ç¤º...")
            demo_ocr_label_integration()
            
    except KeyboardInterrupt:
        print("\n[ä¸­æ–­] ç¨‹åºå·²å®‰å…¨é€€å‡º")
    except Exception as e:
        print(f"\nç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. ç¡®ä¿å·²å®‰è£…tesseract-ocr")
        print("2. æ£€æŸ¥requirements.txtä¸­çš„ä¾èµ–æ˜¯å¦å·²å®‰è£…")
        print("3. ç¡®ä¿å·²æœ‰çš„æ¨¡å—æ–‡ä»¶å­˜åœ¨ä¸”æ­£å¸¸å·¥ä½œ")